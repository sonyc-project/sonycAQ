{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c560dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import elasticsearch\n",
    "import os\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5065b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_over_min = 1\n",
    "days_look_back = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c15b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_date = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "st_date = (datetime.now() - timedelta(days=days_look_back)).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "en_date_dt = datetime.now().astimezone(pytz.timezone('America/New_York'))\n",
    "st_date_dt = (datetime.now() - timedelta(days=days_look_back)).astimezone(pytz.timezone('America/New_York'))\n",
    "\n",
    "st_date_utc = datetime.strptime(st_date, '%Y-%m-%dT%H:%M:%S').astimezone(pytz.UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "en_date_utc = datetime.strptime(en_date, '%Y-%m-%dT%H:%M:%S').astimezone(pytz.UTC).strftime('%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ccf744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-03T17:22:47Z\n",
      "2022-05-23T17:22:47Z\n",
      "2022-05-23 13:22:47.191293-04:00\n"
     ]
    }
   ],
   "source": [
    "print(st_date_utc)\n",
    "print(en_date_utc)\n",
    "print(en_date_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333a26fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aws.southcoastscience.com/topicMessages?topic=nyu/brooklyn/loc/3/particulates&startTime=2022-02-11T06:38:41.000Z&endTime=2022-03-29T13:55:49.000Z&checkpoint=**:/1:00\n"
     ]
    }
   ],
   "source": [
    "# Import and format Praxis data\n",
    "uri = 'https://aws.southcoastscience.com/topicMessages?topic=nyu/brooklyn/loc/3/particulates&' \\\n",
    "'startTime=2022-02-11T06:38:41.000Z&endTime=2022-03-29T13:55:49.000Z&checkpoint=**:/%i:00' \\\n",
    "% (avg_over_min)\n",
    "print(uri)\n",
    "praxis_df = pd.DataFrame([])\n",
    "\n",
    "while uri != '':\n",
    "    header = {\"authorization\": \"api-key nyu-brooklyn\"}\n",
    "    response = requests.get(uri, headers=header)\n",
    "    json = response.json()\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    data['ts'] = pd.to_datetime([ele['rec'] for ele in json['Items']]).tz_convert(tz='US/Eastern')\n",
    "\n",
    "    data['praxis_pm1_vals'] = [ele['val']['pm1'] for ele in json['Items']]\n",
    "    data['praxis_pm2p5_vals'] = [ele['val']['pm2p5'] for ele in json['Items']]\n",
    "    data['praxis_pm10_vals'] = [ele['val']['pm10'] for ele in json['Items']]\n",
    "\n",
    "    data['praxis_pm1_vals_adj'] = [ele['exg']['rn20']['pm1'] for ele in json['Items']]\n",
    "    data['praxis_pm2p5_vals_adj'] = [ele['exg']['rn20']['pm2p5'] for ele in json['Items']]\n",
    "    data['praxis_pm10_vals_adj'] = [ele['exg']['rn20']['pm10'] for ele in json['Items']]\n",
    "\n",
    "#     praxis_df = pd.DataFrame(data).set_index('ts').resample(avg_over).mean()\n",
    "\n",
    "    if 'next' in json:\n",
    "        uri = json['next']\n",
    "    else:\n",
    "        uri = ''\n",
    "    praxis_df = pd.concat([praxis_df, pd.DataFrame(data)])\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "praxis_df = praxis_df.set_index('ts').resample('%iT' % avg_over_min).mean()\n",
    "#praxis_df = praxis_df.loc[st_date_dt:en_date_dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a47f84df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>praxis_pm1_vals</th>\n",
       "      <th>praxis_pm2p5_vals</th>\n",
       "      <th>praxis_pm10_vals</th>\n",
       "      <th>praxis_pm1_vals_adj</th>\n",
       "      <th>praxis_pm2p5_vals_adj</th>\n",
       "      <th>praxis_pm10_vals_adj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-11 01:39:00-05:00</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-11 01:40:00-05:00</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-11 01:41:00-05:00</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-11 01:42:00-05:00</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-11 01:43:00-05:00</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 09:52:00-04:00</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 09:53:00-04:00</th>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 09:54:00-04:00</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 09:55:00-04:00</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 09:56:00-04:00</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66678 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           praxis_pm1_vals  praxis_pm2p5_vals  \\\n",
       "ts                                                              \n",
       "2022-02-11 01:39:00-05:00              0.5                0.9   \n",
       "2022-02-11 01:40:00-05:00              0.5                1.1   \n",
       "2022-02-11 01:41:00-05:00              0.5                0.9   \n",
       "2022-02-11 01:42:00-05:00              0.5                1.5   \n",
       "2022-02-11 01:43:00-05:00              0.5                1.0   \n",
       "...                                    ...                ...   \n",
       "2022-03-29 09:52:00-04:00              0.8                1.6   \n",
       "2022-03-29 09:53:00-04:00              0.9                2.0   \n",
       "2022-03-29 09:54:00-04:00              0.9                1.9   \n",
       "2022-03-29 09:55:00-04:00              0.9                1.7   \n",
       "2022-03-29 09:56:00-04:00              0.9                1.9   \n",
       "\n",
       "                           praxis_pm10_vals  praxis_pm1_vals_adj  \\\n",
       "ts                                                                 \n",
       "2022-02-11 01:39:00-05:00               6.3                  3.2   \n",
       "2022-02-11 01:40:00-05:00               7.7                  3.4   \n",
       "2022-02-11 01:41:00-05:00               1.9                  3.6   \n",
       "2022-02-11 01:42:00-05:00               8.5                  3.2   \n",
       "2022-02-11 01:43:00-05:00               3.2                  3.3   \n",
       "...                                     ...                  ...   \n",
       "2022-03-29 09:52:00-04:00               2.9                  1.2   \n",
       "2022-03-29 09:53:00-04:00              10.5                  1.4   \n",
       "2022-03-29 09:54:00-04:00               7.0                  1.7   \n",
       "2022-03-29 09:55:00-04:00               2.6                  1.5   \n",
       "2022-03-29 09:56:00-04:00               7.2                  1.8   \n",
       "\n",
       "                           praxis_pm2p5_vals_adj  praxis_pm10_vals_adj  \n",
       "ts                                                                      \n",
       "2022-02-11 01:39:00-05:00                    3.8                   9.3  \n",
       "2022-02-11 01:40:00-05:00                    4.6                  13.6  \n",
       "2022-02-11 01:41:00-05:00                    4.3                   7.9  \n",
       "2022-02-11 01:42:00-05:00                    4.8                  20.1  \n",
       "2022-02-11 01:43:00-05:00                    4.0                   9.5  \n",
       "...                                          ...                   ...  \n",
       "2022-03-29 09:52:00-04:00                    2.1                   5.5  \n",
       "2022-03-29 09:53:00-04:00                    2.3                   8.7  \n",
       "2022-03-29 09:54:00-04:00                    3.0                   9.8  \n",
       "2022-03-29 09:55:00-04:00                    2.8                   7.1  \n",
       "2022-03-29 09:56:00-04:00                    2.9                  11.2  \n",
       "\n",
       "[66678 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "praxis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45a4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_time =\"2022-03-29 10:55:00-04:00\"\n",
    "# praxis_df2 = praxis_df.loc['2022-03-29 09:56:00-04:00':'2022-03-29 10:55:00-04:00']\n",
    "praxis_df2 = praxis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dce0c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and format Piera Canary data\n",
    "# 168\n",
    "canary_df = pd.DataFrame([])\n",
    "\n",
    "for x in range(840):\n",
    "    uri = 'https://sensei.pierasystems.com/api/get-minute-averages/318?page=%i' % x\n",
    "    response = requests.get(uri)\n",
    "    json = response.json()\n",
    "    data = {}\n",
    "    if json[\"data\"] == \"\":\n",
    "        break\n",
    "    data['ts'] = pd.to_datetime([ele['time'] for ele in json['data']]).tz_convert(tz='US/Eastern')\n",
    "    \n",
    "    data['canary_pm1_vals'] = [ele['pm10'] for ele in json['data']]\n",
    "    data['canary_pm2p5_vals'] = [ele['pm25'] for ele in json['data']]\n",
    "    data['canary_pm10_vals'] = [ele['pm100'] for ele in json['data']]\n",
    "    data['canary_temp'] = [ele['temp'] for ele in json['data']]\n",
    "    data['canary_rh'] = [ele['rh'] for ele in json['data']]\n",
    "    \n",
    "    canary_df = pd.concat([canary_df, pd.DataFrame(data)])\n",
    "\n",
    "    # if canary_df['ts'].iloc[-1] < pd.DatetimeIndex([st_date_dt]):\n",
    "    #     break\n",
    "    # time.sleep(0.5)\n",
    "    \n",
    "canary_df = canary_df.set_index('ts').resample('%iT' % avg_over_min).mean()\n",
    "# canary_df = canary_df.loc[st_date_dt:en_date_dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cae88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st_date_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "canary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12639bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "P =plt.plot(praxis_df2.index,praxis_df2[\"praxis_pm2p5_vals_adj\"]) ##BLUE\n",
    "P =plt.plot(canary_df.index,canary_df[\"canary_pm2p5_vals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'https://api.thingspeak.com/channels/1530870/feeds.json?api_key=U4IJYTKQ1ON601M3&average=%i&days=%i' \\\n",
    "% (avg_over_min, days_look_back)\n",
    "print(uri)\n",
    "response = requests.get(uri)\n",
    "json = response.json()\n",
    "data = {}\n",
    "data['ts'] = pd.to_datetime([ele['created_at'] for ele in json['feeds']]).tz_convert(tz='US/Eastern')\n",
    "    \n",
    "data['purple_pm1_vals'] = [ele['field1'] for ele in json['feeds']]\n",
    "data['purple_pm2p5_vals'] = [ele['field2'] for ele in json['feeds']]\n",
    "data['purple_pm10_vals'] = [ele['field3'] for ele in json['feeds']]\n",
    "\n",
    "purple_df = pd.DataFrame(data)\n",
    "    \n",
    "# purple_df = purple_df.set_index('ts').resample('%iT' % avg_over_min).mean().interpolate(method='pad', limit=2)\n",
    "purple_df = purple_df.set_index('ts').resample('%iT' % avg_over_min).mean()\n",
    "purple_df = purple_df.loc[st_date_dt:en_date_dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a729aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "purple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9aa2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = canary_df.join(praxis_df)\n",
    "comb_df = comb_df.join(purple_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP = time.time()\n",
    "\n",
    "def scroll(es, index, body, scroll='2m', size=1000, timeout=25, **kw):\n",
    "    if isinstance(timeout, int):\n",
    "        timeout = '{}s'.format(int(timeout))\n",
    "    page = es.search(index=index, body=body, scroll=scroll, size=size, timeout=timeout, **kw)\n",
    "    scroll_id, hits = page['_scroll_id'], page['hits']['hits']\n",
    "    while len(hits):\n",
    "        yield hits\n",
    "        page = es.scroll(scroll_id=scroll_id, scroll=scroll)\n",
    "        scroll_id, hits = page['_scroll_id'], page['hits']['hits']\n",
    "        \n",
    "def sensor_query(key=None, nodeid=None, start=None, end=None, k_time=\"time\", group=GROUP):\n",
    "    match = []\n",
    "    if key and nodeid:\n",
    "        match.append({\"term\": {f'{key}.keyword': nodeid}})\n",
    "    end = end or 'now'\n",
    "    if start:\n",
    "        match.append({\"range\" : {k_time : {\"gte\" : start, \"lte\" : end}}})\n",
    "    elif end:\n",
    "        match.append({\"range\" : {k_time : {\"lte\" : end}}})\n",
    "    return { \"query\": { \"bool\": {\"must\": match} } } if match else {}\n",
    "\n",
    "def download_sensor_data(table, key=None, nodeid=None, start=None, end=None, save=True, k_time='time', **kw):\n",
    "    query = sensor_query(key, nodeid, start, end, k_time=k_time, **kw)\n",
    "    print(query)\n",
    "    \n",
    "    def pull():\n",
    "        with tqdm(scroll(es, table, query)) as pbar:\n",
    "            for i, hits in enumerate(pbar):\n",
    "                hits = [h['_source'] for h in hits]\n",
    "                times = [h[k_time] for h in hits]\n",
    "                pbar.write('{}. n hits: {}. {} - {}'.format(i, len(hits), min(times), max(times)))\n",
    "                for h in hits:\n",
    "                    yield h\n",
    "    if not save:\n",
    "        return list(pull())\n",
    "\n",
    "    fname = 'data/{}/{}.json'.format(group, nodeid or table)\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "    print(f'Pulling node={nodeid} for ({start} -> {end}) ... saving to {fname}')\n",
    "    with open(fname, 'w') as f:\n",
    "        for h in pull():\n",
    "            f.write(json.dumps(h) + '\\n')\n",
    "    print('all done!')\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss[0]['aq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1669ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = comb_df[['canary_pm2p5_vals', 'praxis_pm2p5_vals_adj', 'praxis_pm2p5_vals', 'purple_pm2p5_vals', 'piera7100_pm2p5_vals']].plot();\n",
    "fig = comb_df[['canary_pm2p5_vals', 'praxis_pm2p5_vals_adj', 'praxis_pm2p5_vals', 'purple_pm2p5_vals']].plot();\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "df_main = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': canary_df[\"canary_pm2p5_vals\"], 'Temp': canary_df[\"canary_temp\"], 'RelHum': canary_df[\"canary_rh\"]})\n",
    "\n",
    "X = df_main[['Sensor_O1','Temp', 'RelHum']]\n",
    "Y = df_main['RefSt']\n",
    "X = X.fillna(X.mean())\n",
    "Y =Y.fillna(Y.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MLRtrain, X_MLRtest, Y_MLRtrain, Y_MLRtest = train_test_split(X, Y, test_size = 0.4, random_state = 1, shuffle = False)\n",
    "\n",
    "# ee = OneClassSVM(nu=0.51)\n",
    "# yhat = ee.fit_predict(X_MLRtrain)\n",
    "# # select all rows that are not outliers\n",
    "# mask = yhat != -1\n",
    "# X_MLRtrain, Y_MLRtrain = X_MLRtrain[mask], Y_MLRtrain[mask]\n",
    "\n",
    "\n",
    "df_MLRtrain = pd.DataFrame({'RefSt': Y_MLRtrain, 'Sensor_O1': X_MLRtrain[\"Sensor_O1\"],'Temp': X_MLRtrain[\"Temp\"], 'RelHum': X_MLRtrain[\"RelHum\"]})\n",
    "df_MLRtest = pd.DataFrame({'RefSt': Y_MLRtest, 'Sensor_O1': X_MLRtest[\"Sensor_O1\"],'Temp': X_MLRtest[\"Temp\"], 'RelHum': X_MLRtest[\"RelHum\"]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def loss_functions(y_true, y_pred):\n",
    "    print(\"Loss functions:\")\n",
    "    print(\"* R-squared =\", r2_score(y_true, y_pred))\n",
    "    print(\"* RMSE =\", mean_squared_error(y_true, y_pred))\n",
    "    print(\"* MAE =\", mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "# %%\n",
    "# Normalise sensor data\n",
    "def normalize(col):\n",
    "    μ = col.mean()\n",
    "    sig = col.std()\n",
    "    return (col - μ)/sig\n",
    "\n",
    "df_main[\"normRefSt\"] = normalize(df_main[\"RefSt\"])\n",
    "df_main[\"normSensor_O3\"] = normalize(df_main[\"Sensor_O1\"])\n",
    "df_main[\"normTemp\"] = normalize(df_main[\"Temp\"])\n",
    "df_main[\"normRelHum\"] = normalize(df_main[\"RelHum\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61ddbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensor_O3_RefSt_factor = df_main[[\"Sensor_O1\", \"RefSt\"]]\n",
    "#Sensor_O3_RefSt_factor[\"RefSt\"] = Sensor_O3_RefSt_factor[\"RefSt\"]\n",
    "Sensor_O3_RefSt_factor.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, Y_train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634cd426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "# Model\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "# Fit\n",
    "lr.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# Get MLR coefficients\n",
    "print('Intercept: \\n', lr.intercept_)\n",
    "print('Coefficients: \\n', lr.coef_)\n",
    "\n",
    "# Predict\n",
    "df_MLRtest[\"MLR_Pred\"] = lr.intercept_ + lr.coef_[0]*df_MLRtest[\"Sensor_O1\"] + lr.coef_[1]*df_MLRtest[\"Temp\"] + lr.coef_[2]*df_MLRtest[\"RelHum\"]\n",
    "\n",
    "# Plot linear\n",
    "df_MLRtest[[\"RefSt\", \"MLR_Pred\"]].plot()\n",
    "print(lr.score(X_MLRtrain, Y_MLRtrain))\n",
    "\n",
    "\n",
    "# Plot regression\n",
    "sns.lmplot(x = 'RefSt', y = 'MLR_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"MLR_Pred\"])\n",
    "df_MLRtest[[\"RefSt\", \"MLR_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(praxis_df2.index,praxis_df2[\"praxis_pm2p5_vals_adj\"]) ##BLUE\n",
    "# plt.plot(df_test[\"MLR_Pred\"] )\n",
    "# canary_df.index,canary_df[\"canary_pm2p5_vals\"]##BLUE\n",
    "\n",
    "df2_check = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': df_MLRtest[\"MLR_Pred\"]})\n",
    "Sensor_O3_RefSt = df2_check[[\"Sensor_O1\", \"RefSt\"]]\n",
    "Sensor_O3_RefSt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98dc2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MLR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': canary_df[\"canary_pm2p5_vals\"], 'Temp': canary_df[\"canary_temp\"], 'RelHum': canary_df[\"canary_rh\"]})\n",
    "df_MLR[\"MLR_Pred\"] = lr.intercept_ + lr.coef_[0]*df_MLR[\"Sensor_O1\"] + lr.coef_[1]*df_MLR[\"Temp\"] + lr.coef_[2]*df_MLR[\"RelHum\"]\n",
    "df_MLR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': df_MLR[\"MLR_Pred\"]})\n",
    "Sensor_plot = df_MLR[[\"Sensor_O1\", \"RefSt\"]]\n",
    "Sensor_plot.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf09bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Model\n",
    "# sgdr = SGDRegressor(loss='squared_loss', alpha=.001, tol=1e-5)\n",
    "sgdr = SGDRegressor(loss = 'squared_loss', max_iter = 5)\n",
    "\n",
    "# Normalize\n",
    "sc = StandardScaler()\n",
    "X_MLR_SGDtrain = sc.fit_transform(X_MLRtrain)\n",
    "X_MLR_SGDtest = sc.transform(X_MLRtest)\n",
    "\n",
    "# Fit\n",
    "sgdr.fit(X_MLR_SGDtrain, Y_MLRtrain)\n",
    "\n",
    "# Get MLR coefficients\n",
    "print('Intercept: \\n', sgdr.intercept_)\n",
    "print('Coefficients: \\n', sgdr.coef_)\n",
    "print('Iters: \\n', sgdr.n_iter_)\n",
    "print(sgdr.get_params())\n",
    "\n",
    "\n",
    "# Predict\n",
    "#df_MLRtest[\"MLR_SGD_Pred\"] = sgdr.intercept_ + sgdr.coef_[0]*df_MLRtest[\"Sensor_O1\"] + sgdr.coef_[1]*df_MLRtest[\"Temp\"]+sgdr.coef_[2]*df_MLRtest[\"RelHum\"]\n",
    "df_MLRtest[\"MLR_SGD_Pred\"] = sgdr.predict(X_MLR_SGDtest)\n",
    "\n",
    "# Plot linear\n",
    "df_MLRtest[[\"RefSt\", \"MLR_SGD_Pred\"]].plot()\n",
    "\n",
    "\n",
    "# Plot regression\n",
    "sns.lmplot(x = 'RefSt', y = 'MLR_SGD_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"MLR_SGD_Pred\"])\n",
    "df_MLRtest[[\"RefSt\", \"MLR_SGD_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# K-Nearest Neighbor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Model\n",
    "knn = KNeighborsRegressor(n_neighbors = 19)\n",
    "\n",
    "# Fit\n",
    "knn.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# Predict\n",
    "df_MLRtest[\"KNN_Pred\"] = knn.predict(X_MLRtest)\n",
    "# print(df_MLRtest)\n",
    "\n",
    "# Plot linear\n",
    "# df_MLRtest[[\"RefSt\", \"KNN_Pred\"]].plot()\n",
    "# plt.xticks(rotation=20)\n",
    "\n",
    "# Plot regression\n",
    "# sns.lmplot(x = 'RefSt', y = 'KNN_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"KNN_Pred\"])\n",
    "df_MLRtest[[\"RefSt\", \"KNN_Pred\"]].plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6cc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% uncomment to run KNN with hyper parameters\n",
    "# # K-Nearest Neighbor stats vs. hyperparameters\n",
    "# def knn_stats():\n",
    "#     knn_aux = pd.DataFrame({'RefSt': Y_MLRtest})\n",
    "\n",
    "#     n_neighbors = [*range(1, 151, 1)]\n",
    "#     r_squared = []\n",
    "#     rmse = []\n",
    "#     mae = []\n",
    "#     time_ms = []\n",
    "\n",
    "#     for i in n_neighbors:\n",
    "#         # Model\n",
    "#         knn = KNeighborsRegressor(n_neighbors=i)\n",
    "\n",
    "#         # Fit\n",
    "#         start_time = float(datetime.now().strftime('%S.%f'))\n",
    "#         knn.fit(X_MLRtrain, Y_MLRtrain)\n",
    "#         end_time = float(datetime.now().strftime('%S.%f'))\n",
    "#         execution_time = (end_time - start_time) * 1000\n",
    "\n",
    "#         # Predict\n",
    "#         knn_aux[\"KNN_Pred\"] = knn.predict(X_MLRtest)\n",
    "        \n",
    "\n",
    "#         # Loss\n",
    "#         r_squared.append(r2_score(knn_aux[\"RefSt\"], knn_aux[\"KNN_Pred\"]))\n",
    "#         rmse.append(mean_squared_error(knn_aux[\"RefSt\"], knn_aux[\"KNN_Pred\"]))\n",
    "#         mae.append(mean_absolute_error(knn_aux[\"RefSt\"], knn_aux[\"KNN_Pred\"]))\n",
    "#         time_ms.append(execution_time)\n",
    "\n",
    "#     knn_stats = pd.DataFrame({'k': n_neighbors, 'r_squared': r_squared, 'rmse': rmse, 'mae': mae, 'time_ms': time_ms})\n",
    "#     knn_stats = knn_stats.set_index('k') # index column (X axis for the plots)\n",
    "#     print(knn_stats)\n",
    "#     plt.plot(knn_aux[[\"RefSt\", \"KNN_Pred\"]])\n",
    "#     # plot\n",
    "#     # knn_stats[[\"r_squared\"]].plot()\n",
    "#     # knn_stats[[\"rmse\"]].plot()\n",
    "#     # knn_stats[[\"mae\"]].plot()\n",
    "#     # knn_stats[[\"time_ms\"]].plot()\n",
    "    \n",
    "# knn_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda00e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KNN = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': canary_df[\"canary_pm2p5_vals\"], 'Temp': canary_df[\"canary_temp\"], 'RelHum': canary_df[\"canary_rh\"]})\n",
    "df_KNN[\"KNN\"] = knn.predict(X)\n",
    "df_KNN = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_KNN': df_KNN[\"KNN\"]})\n",
    "Sensor_plot_KNN = df_KNN[[\"RefSt\",\"Sensor_KNN\"]]\n",
    "Sensor_plot_KNN.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Model\n",
    "rf = RandomForestRegressor(n_estimators = 20 ,random_state = 0)\n",
    "\n",
    "# Fit\n",
    "rf.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# Predict\n",
    "df_MLRtest[\"RF_Pred\"] = rf.predict(X_MLRtest)\n",
    "# print(df_MLRtest)\n",
    "\n",
    "# Plot linear\n",
    "# df_MLRtest[[\"RefSt\", \"RF_Pred\"]].plot()\n",
    "# plt.xticks(rotation = 20)\n",
    "\n",
    "# Plot regression\n",
    "# sns.lmplot(x = 'RefSt', y = 'RF_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"RF_Pred\"])\n",
    "\n",
    "# RF feature importances\n",
    "print('Feature importances:\\n', list(zip(X.columns, rf.feature_importances_)))\n",
    "df_MLRtest[[\"RefSt\", \"RF_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RF = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': canary_df[\"canary_pm2p5_vals\"], 'Temp': canary_df[\"canary_temp\"], 'RelHum': canary_df[\"canary_rh\"]})\n",
    "df_RF[\"RF\"] = rf.predict(X)\n",
    "df_RF = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_RF': df_RF[\"RF\"]})\n",
    "Sensor_plot_RF = df_RF[[\"RefSt\", \"Sensor_RF\"]]\n",
    "Sensor_plot_RF.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20660fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['Sensor_O1','Temp', 'RelHum']\n",
    "# d = {'Sensor_O1': [0.1], 'Temp': [0.2], 'RelHum': [0.3]}\n",
    "# ddd = pd.DataFrame(data=d)\n",
    "# rf.predict(ddd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # Kernel Regression\n",
    "# # from sklearn_extensions.kernel_regression import KernelRegression\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# # Models\n",
    "# kr_rbf = KernelRidge(kernel = \"rbf\")\n",
    "# kr_poly = KernelRidge(kernel = \"poly\", degree = 4)\n",
    "\n",
    "# # Fit\n",
    "# kr_rbf.fit(X_MLRtrain, Y_MLRtrain)\n",
    "# kr_poly.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# # Predict\n",
    "# df_MLRtest[\"KR_RBF_Pred\"] = kr_rbf.predict(X_MLRtest)\n",
    "# df_MLRtest[\"KR_Poly_Pred\"] = kr_poly.predict(X_MLRtest)\n",
    "\n",
    "# # Plot linear\n",
    "# df_MLRtest[[\"RefSt\", \"KR_RBF_Pred\", \"KR_Poly_Pred\"]].plot()\n",
    "# plt.xticks(rotation=20)\n",
    "\n",
    "# # Plot regression\n",
    "# sns.lmplot(x = 'RefSt', y = 'KR_RBF_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "# sns.lmplot(x = 'RefSt', y = 'KR_Poly_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# # Loss\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"KR_RBF_Pred\"])\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"KR_Poly_Pred\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c318ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # Gaussian Process\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import ConstantKernel, RBF, DotProduct, WhiteKernel\n",
    "\n",
    "# # Kernels definition\n",
    "# # rbf = ConstantKernel(constant_value=1.0, constant_value_bounds=(1e-10, 1e10)) * RBF(length_scale=1.0, length_scale_bounds=(1e-10, 1e10))\n",
    "# rbf = ConstantKernel() * RBF()\n",
    "# dpwh = DotProduct() + WhiteKernel()\n",
    "\n",
    "# # Models\n",
    "# gp_rbf = GaussianProcessRegressor(kernel = rbf, alpha = 150, random_state = 0)\n",
    "# gp_dpwh = GaussianProcessRegressor(kernel = dpwh, alpha = 150, random_state = 0)\n",
    "\n",
    "# # Fit\n",
    "# gp_rbf.fit(X_MLRtrain, Y_MLRtrain)\n",
    "# gp_dpwh.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# # Predict\n",
    "# df_MLRtest[\"GP_RBF_Pred\"] = gp_rbf.predict(X_MLRtest)\n",
    "# df_MLRtest[\"GP_DPWK_Pred\"] = gp_dpwh.predict(X_MLRtest)\n",
    "\n",
    "# # Obtain optimized kernel parameters\n",
    "# # l = gp.kernel_.k2.get_params()['length_scale']\n",
    "# # sigma_f = np.sqrt(gp.kernel_.k1.get_params()['constant_value'])\n",
    "\n",
    "# # Print parameters\n",
    "# print(\"RBF params\", gp_rbf.get_params())\n",
    "# print(\"Dot params\", gp_dpwh.get_params())\n",
    "\n",
    "# # Plot linear\n",
    "# df_MLRtest[[\"RefSt\", \"GP_RBF_Pred\", \"GP_DPWK_Pred\"]].plot()\n",
    "# plt.xticks(rotation = 20)\n",
    "\n",
    "# # Plot regression\n",
    "# sns.lmplot(x = 'RefSt', y = 'GP_RBF_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "# sns.lmplot(x = 'RefSt', y = 'GP_DPWK_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# # Loss\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"GP_RBF_Pred\"])\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"GP_DPWK_Pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e84625",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using radial basis function kernel\n",
    "# Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Models\n",
    "svr_rbf = SVR(kernel = 'rbf', C = 1e3)#, gamma=0.1)\n",
    "\n",
    "# Fit\n",
    "svr_rbf.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "print('Intercept: \\n', svr_rbf.intercept_)\n",
    "\n",
    "# Predict\n",
    "df_MLRtest[\"SVR_RBF_Pred\"] = svr_rbf.predict(X_MLRtest)\n",
    "\n",
    "# Plot regression\n",
    "sns.lmplot(x = 'RefSt', y = 'SVR_RBF_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"SVR_RBF_Pred\"])\n",
    "\n",
    "df_MLRtest[[\"RefSt\", \"SVR_RBF_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51570e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Not Ideal as it will take a lot of time to compute\n",
    "# # Support Vector Regression\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "# # Models\n",
    "# svr_lin = SVR(kernel = 'linear', C = 1e3)\n",
    "\n",
    "\n",
    "# # Fit\n",
    "\n",
    "# svr_lin.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# print('Intercept: \\n', svr_lin.intercept_)\n",
    "# # print('Coefficients: \\n', svr_lin.coef_)\n",
    "\n",
    "# # Predict\n",
    "# df_MLRtest[\"SVR_Line_Pred\"] = svr_lin.predict(X_MLRtest)\n",
    "\n",
    "\n",
    "# # Plot regression\n",
    "# sns.lmplot(x = 'RefSt', y = 'SVR_Line_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "\n",
    "# # Loss\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"SVR_Line_Pred\"])\n",
    "\n",
    "# df_MLRtest[[\"RefSt\", \"SVR_Line_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6426f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Support Vector Regression using poly (Not Ideal as it takes a lot of time to train)\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "# # Models\n",
    "# svr_poly = SVR(kernel = 'poly', C = 1e3, degree = 3)\n",
    "\n",
    "# # Fit\n",
    "# svr_poly.fit(X_MLRtrain, Y_MLRtrain)\n",
    "# print('Intercept: \\n', svr_poly.intercept_)\n",
    "# #print('Coefficients: \\n', svr_poly.coef_)\n",
    "\n",
    "# # Predict\n",
    "# df_MLRtest[\"SVR_Poly_Pred\"] = svr_poly.predict(X_MLRtest)\n",
    "\n",
    "# # Plot regression\n",
    "\n",
    "# sns.lmplot(x = 'RefSt', y = 'SVR_Poly_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# # Loss\n",
    "\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"SVR_Poly_Pred\"])\n",
    "# df_MLRtest[[\"RefSt\", \"SVR_Poly_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SVR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': canary_df[\"canary_pm2p5_vals\"], 'Temp': canary_df[\"canary_temp\"], 'RelHum': canary_df[\"canary_rh\"]})\n",
    "# df_SVR[\"SVR_rbf\"] = svr_rbf.predict(X)\n",
    "# # df_SVR[\"SVR_lin\"] = svr_lin.predict(X)\n",
    "# # df_SVR[\"SVR_poly\"] = svr_poly.predict(X)\n",
    "# df_SVR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_RF': df_SVR[\"SVR_rbf\"]})\n",
    "# # df_SVR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_RF_rbf': df_SVR[\"SVR_rbf\"], 'Sensor_RF_lin': df_SVR[\"SVR_lin\"], 'Sensor_RF_poly': df_SVR[\"SVR_poly\"]})\n",
    "# Sensor_plot_SVR = df_SVR[[\"Sensor_RF\", \"RefSt\"]]\n",
    "# Sensor_plot_SVR.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Normalise data\n",
    "sc = StandardScaler()\n",
    "X_train_NN = sc.fit_transform(X_MLRtrain)\n",
    "X_test_NN = sc.transform(X_MLRtest)\n",
    "Y_MLRtrain_NN = Y_MLRtrain\n",
    "# Model\n",
    "nn = Sequential()\n",
    "\n",
    "# Model - Layers\n",
    "nn.add(InputLayer(input_shape = (3))) # Input layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 1st hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 2nd hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 3rd hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 4th hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 5th hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 4th hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 5th hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 6th hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 7th hidden layer\n",
    "nn.add(Dense(units = 1)) # Output layer\n",
    "\n",
    "nn.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fit\n",
    "history = nn.fit(X_train_NN, Y_MLRtrain_NN, batch_size = 10, epochs = 50)\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history['loss'][5:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Predict\n",
    "df_MLRtest[\"NN_Pred\"] = nn.predict(X_MLRtest)\n",
    "print(df_MLRtest)\n",
    "\n",
    "# Plot linear\n",
    "df_MLRtest[[\"RefSt\", \"NN_Pred\"]].plot()\n",
    "plt.xticks(rotation=20)\n",
    "\n",
    "# Plot regression\n",
    "sns.lmplot(x = 'RefSt', y = 'NN_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"NN_Pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SVR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': canary_df[\"canary_pm2p5_vals\"], 'Temp': canary_df[\"canary_temp\"], 'RelHum': canary_df[\"canary_rh\"]})\n",
    "# df_SVR[\"SVR_rbf\"] = svr_rbf.predict(X)\n",
    "# df_SVR[\"SVR_lin\"] = svr_lin.predict(X)\n",
    "# df_SVR[\"SVR_poly\"] = svr_poly.predict(X)\n",
    "df_NN = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_NN': df_MLRtest[\"NN_Pred\"]})\n",
    "# df_SVR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_RF_rbf': df_SVR[\"SVR_rbf\"], 'Sensor_RF_lin': df_SVR[\"SVR_lin\"], 'Sensor_RF_poly': df_SVR[\"SVR_poly\"]})\n",
    "Sensor_plot_NN = df_NN[[\"Sensor_NN\", \"RefSt\"]]\n",
    "Sensor_plot_NN.plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "sonycAQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
