{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import elasticsearch\n",
    "import os\n",
    "pd.options.plotting.backend = \"plotly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_over_min = 1\n",
    "days_look_back = 30\n",
    "en_date = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "st_date = (datetime.now() - timedelta(days=days_look_back)).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "en_date_dt = datetime.now().astimezone(pytz.timezone('America/New_York'))\n",
    "st_date_dt = (datetime.now() - timedelta(days=days_look_back)).astimezone(pytz.timezone('America/New_York'))\n",
    "\n",
    "st_date_utc = datetime.strptime(st_date, '%Y-%m-%dT%H:%M:%S').astimezone(pytz.UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "en_date_utc = datetime.strptime(en_date, '%Y-%m-%dT%H:%M:%S').astimezone(pytz.UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filePath = glob.glob('*.csv')\n",
    "for i in filePath:\n",
    "    if os.path.exists(i):\n",
    "        os.remove(i)\n",
    "    else:\n",
    "        print(\"Can not delete the file as it doesn't exists\")\n",
    "os.system('python3 weather_scraper.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and format Praxis data\n",
    "\n",
    "uri = 'https://aws.southcoastscience.com/topicMessages?topic=nyu/brooklyn/loc/3/particulates&' \\\n",
    "'startTime=%s&endTime=%s&checkpoint=**:/%i:00' \\\n",
    "% (st_date_utc, en_date_utc, avg_over_min)\n",
    "print(uri)\n",
    "praxis_df = pd.DataFrame([])\n",
    "\n",
    "while uri != '':\n",
    "    header = {\"authorization\": \"api-key nyu-brooklyn\"}\n",
    "    response = requests.get(uri, headers=header)\n",
    "    json = response.json()\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    data['ts'] = pd.to_datetime([ele['rec'] for ele in json['Items']]).tz_convert(tz='US/Eastern')\n",
    "\n",
    "    data['praxis_pm1_vals'] = [ele['val']['pm1'] for ele in json['Items']]\n",
    "    data['praxis_pm2p5_vals'] = [ele['val']['pm2p5'] for ele in json['Items']]\n",
    "    data['praxis_pm10_vals'] = [ele['val']['pm10'] for ele in json['Items']]\n",
    "\n",
    "    data['praxis_pm1_vals_adj'] = [ele['exg']['rn20']['pm1'] for ele in json['Items']]\n",
    "    data['praxis_pm2p5_vals_adj'] = [ele['exg']['rn20']['pm2p5'] for ele in json['Items']]\n",
    "    data['praxis_pm10_vals_adj'] = [ele['exg']['rn20']['pm10'] for ele in json['Items']]\n",
    "\n",
    "#     praxis_df = pd.DataFrame(data).set_index('ts').resample(avg_over).mean()\n",
    "\n",
    "    if 'next' in json:\n",
    "        uri = json['next']\n",
    "    else:\n",
    "        uri = ''\n",
    "    praxis_df = pd.concat([praxis_df, pd.DataFrame(data)])\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "praxis_df = praxis_df.set_index('ts').resample('%iT' % avg_over_min).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praxis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv(glob.glob('*.csv')[0])\n",
    "print(df_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_weather['ts'] = pd.to_datetime(df_weather['Date'] + ' ' + df_weather['Time']).dt.tz_localize(tz='US/Eastern')\n",
    "# df_weather = df_weather.set_index('ts').resample('%iT' % avg_over_min).mean()\n",
    "# df_weather = df_weather.fillna(df_weather.mean())\n",
    "df_weather['ts'] =pd.to_datetime(df_weather[\"Date\"] + ' ' + df_weather['Time']).dt.tz_localize(tz='US/Eastern')\n",
    "df_weather= df_weather.set_index('ts').resample('%iT' % avg_over_min).mean().fillna(df_weather.mean())\n",
    "df_weather = df_weather.loc[st_date:en_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_weather.tail() \n",
    "\n",
    "df_weather = df_weather[['Temperature_C', 'Humidity_%']]\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praxis_df = praxis_df.loc[str(df_weather.index[0]):str(df_weather.index[-1])]\n",
    "praxis_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP = time.time()\n",
    "\n",
    "def scroll(es, index, body, scroll='2m', size=1000, timeout=25, **kw):\n",
    "    if isinstance(timeout, int):\n",
    "        timeout = '{}s'.format(int(timeout))\n",
    "    page = es.search(index=index, body=body, scroll=scroll, size=size, timeout=timeout, **kw)\n",
    "    scroll_id, hits = page['_scroll_id'], page['hits']['hits']\n",
    "    while len(hits):\n",
    "        yield hits\n",
    "        page = es.scroll(scroll_id=scroll_id, scroll=scroll)\n",
    "        scroll_id, hits = page['_scroll_id'], page['hits']['hits']\n",
    "        \n",
    "def sensor_query(key=None, nodeid=None, start=None, end=None, k_time=\"time\", group=GROUP):\n",
    "    match = []\n",
    "    if key and nodeid:\n",
    "        match.append({\"term\": {f'{key}.keyword': nodeid}})\n",
    "    end = end or 'now'\n",
    "    if start:\n",
    "        match.append({\"range\" : {k_time : {\"gte\" : start, \"lte\" : end}}})\n",
    "    elif end:\n",
    "        match.append({\"range\" : {k_time : {\"lte\" : end}}})\n",
    "    return { \"query\": { \"bool\": {\"must\": match} } } if match else {}\n",
    "\n",
    "def download_sensor_data(table, key=None, nodeid=None, start=None, end=None, save=True, k_time='time', **kw):\n",
    "    query = sensor_query(key, nodeid, start, end, k_time=k_time, **kw)\n",
    "    print(query)\n",
    "    \n",
    "    def pull():\n",
    "        with tqdm(scroll(es, table, query)) as pbar:\n",
    "            for i, hits in enumerate(pbar):\n",
    "                hits = [h['_source'] for h in hits]\n",
    "                times = [h[k_time] for h in hits]\n",
    "                pbar.write('{}. n hits: {}. {} - {}'.format(i, len(hits), min(times), max(times)))\n",
    "                for h in hits:\n",
    "                    yield h\n",
    "    if not save:\n",
    "        return list(pull())\n",
    "\n",
    "    fname = 'data/{}/{}.json'.format(group, nodeid or table)\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "    print(f'Pulling node={nodeid} for ({start} -> {end}) ... saving to {fname}')\n",
    "    with open(fname, 'w') as f:\n",
    "        for h in pull():\n",
    "            f.write(json.dumps(h) + '\\n')\n",
    "    print('all done!')\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import settings\n",
    "reload(settings)\n",
    "es = elasticsearch.Elasticsearch('https://es.master1.sonycproject.com', http_auth=('elastic', settings.es_password))\n",
    "ss = download_sensor_data('status', 'fqdn', 'sonycnode-dca632ceb490', start='now-%id' % (days_look_back+1), save=False)\n",
    "data = {}\n",
    "data['ts'] = pd.to_datetime([datetime.fromtimestamp(int(ele['aq']['dt'])) for ele in ss]).tz_localize(tz='US/Eastern')\n",
    "    \n",
    "data['piera7100_pm1_vals'] = [ele['aq']['PM1.0'] for ele in ss]\n",
    "data['piera7100_pm2p5_vals'] = [ele['aq']['PM2.5'] for ele in ss]\n",
    "data['piera7100_pm10_vals'] = [ele['aq']['PM10'] for ele in ss]\n",
    "\n",
    "piera7100_df = pd.DataFrame(data)\n",
    "    \n",
    "piera7100_df = piera7100_df.set_index('ts').resample('%iT' % avg_over_min).mean()\n",
    "# purple_df = purple_df.set_index('ts').resample('%iT' % avg_over_min).mean()\n",
    "# piera7100_df = piera7100_df.loc[st_date_dt:en_date_dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piera7100_df = piera7100_df[str(df_weather.index[0]):str(df_weather.index[-1])]\n",
    "piera7100_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "df_main = pd.DataFrame({'RefSt': praxis_df[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': piera7100_df[\"piera7100_pm2p5_vals\"], 'Temp': df_weather[\"Temperature_C\"], 'RelHum': df_weather[\"Humidity_%\"]})\n",
    "\n",
    "X = df_main[['Sensor_O1','Temp', 'RelHum']]\n",
    "Y = df_main['RefSt']\n",
    "X = X.fillna(X.mean())\n",
    "Y =Y.fillna(Y.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MLRtrain, X_MLRtest, Y_MLRtrain, Y_MLRtest = train_test_split(X, Y, test_size = 0.33, random_state = None, shuffle = False)\n",
    "\n",
    "# ee = OneClassSVM(nu=0.51)\n",
    "# yhat = ee.fit_predict(X_MLRtrain)\n",
    "# # select all rows that are not outliers\n",
    "# mask = yhat != -1\n",
    "# X_MLRtrain, Y_MLRtrain = X_MLRtrain[mask], Y_MLRtrain[mask]\n",
    "\n",
    "\n",
    "df_MLRtrain = pd.DataFrame({'RefSt': Y_MLRtrain, 'Sensor_O1': X_MLRtrain[\"Sensor_O1\"],'Temp': X_MLRtrain[\"Temp\"], 'RelHum': X_MLRtrain[\"RelHum\"]})\n",
    "df_MLRtest = pd.DataFrame({'RefSt': Y_MLRtest, 'Sensor_O1': X_MLRtest[\"Sensor_O1\"],'Temp': X_MLRtest[\"Temp\"], 'RelHum': X_MLRtest[\"RelHum\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def loss_functions(y_true, y_pred):\n",
    "    print(\"Loss functions:\")\n",
    "    print(\"* R-squared =\", r2_score(y_true, y_pred))\n",
    "    print(\"* RMSE =\", mean_squared_error(y_true, y_pred))\n",
    "    print(\"* MAE =\", mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "# %%\n",
    "# Normalise sensor data\n",
    "def normalize(col):\n",
    "    μ = col.mean()\n",
    "    sig = col.std()\n",
    "    return (col - μ)/sig\n",
    "\n",
    "df_main[\"normRefSt\"] = normalize(df_main[\"RefSt\"])\n",
    "df_main[\"normSensor_O3\"] = normalize(df_main[\"Sensor_O1\"])\n",
    "df_main[\"normTemp\"] = normalize(df_main[\"Temp\"])\n",
    "df_main[\"normRelHum\"] = normalize(df_main[\"RelHum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensor_O3_RefSt_factor = df_main[[\"Sensor_O1\", \"RefSt\"]]\n",
    "#Sensor_O3_RefSt_factor[\"RefSt\"] = Sensor_O3_RefSt_factor[\"RefSt\"]\n",
    "Sensor_O3_RefSt_factor.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "# Model\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "# Fit\n",
    "lr.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# Get MLR coefficients\n",
    "print('Intercept: \\n', lr.intercept_)\n",
    "print('Coefficients: \\n', lr.coef_)\n",
    "\n",
    "# Predict\n",
    "df_MLRtest[\"MLR_Pred\"] = lr.intercept_ + lr.coef_[0]*df_MLRtest[\"Sensor_O1\"] + lr.coef_[1]*df_MLRtest[\"Temp\"] + lr.coef_[2]*df_MLRtest[\"RelHum\"]\n",
    "\n",
    "# Plot linear\n",
    "df_MLRtest[[\"RefSt\", \"MLR_Pred\"]].plot()\n",
    "print(lr.score(X_MLRtrain, Y_MLRtrain))\n",
    "\n",
    "\n",
    "# Plot regression\n",
    "sns.lmplot(x = 'RefSt', y = 'MLR_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"MLR_Pred\"])\n",
    "df_MLRtest[[\"RefSt\", \"MLR_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,7))\n",
    "plt.plot(df_MLRtest[[\"RefSt\", \"MLR_Pred\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Model\n",
    "# sgdr = SGDRegressor(loss='squared_loss', alpha=.001, tol=1e-5)\n",
    "sgdr = SGDRegressor(loss = 'squared_loss', max_iter = 5)\n",
    "\n",
    "# Normalize\n",
    "sc = StandardScaler()\n",
    "X_MLR_SGDtrain = sc.fit_transform(X_MLRtrain)\n",
    "X_MLR_SGDtest = sc.transform(X_MLRtest)\n",
    "\n",
    "# Fit\n",
    "sgdr.fit(X_MLR_SGDtrain, Y_MLRtrain)\n",
    "\n",
    "# Get MLR coefficients\n",
    "print('Intercept: \\n', sgdr.intercept_)\n",
    "print('Coefficients: \\n', sgdr.coef_)\n",
    "print('Iters: \\n', sgdr.n_iter_)\n",
    "print(sgdr.get_params())\n",
    "\n",
    "\n",
    "# Predict\n",
    "#df_MLRtest[\"MLR_SGD_Pred\"] = sgdr.intercept_ + sgdr.coef_[0]*df_MLRtest[\"Sensor_O1\"] + sgdr.coef_[1]*df_MLRtest[\"Temp\"]+sgdr.coef_[2]*df_MLRtest[\"RelHum\"]\n",
    "df_MLRtest[\"MLR_SGD_Pred\"] = sgdr.predict(X_MLR_SGDtest)\n",
    "\n",
    "# Plot linear\n",
    "df_MLRtest[[\"RefSt\", \"MLR_SGD_Pred\"]].plot()\n",
    "\n",
    "\n",
    "# Plot regression\n",
    "sns.lmplot(x = 'RefSt', y = 'MLR_SGD_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"MLR_SGD_Pred\"])\n",
    "df_MLRtest[[\"RefSt\", \"MLR_SGD_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,7))\n",
    "plt.plot(df_MLRtest[[\"RefSt\", \"MLR_SGD_Pred\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# K-Nearest Neighbor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Model\n",
    "knn = KNeighborsRegressor(n_neighbors = 19)\n",
    "\n",
    "# Fit\n",
    "knn.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# Predict\n",
    "df_MLRtest[\"KNN_Pred\"] = knn.predict(X_MLRtest)\n",
    "# print(df_MLRtest)\n",
    "\n",
    "# Plot linear\n",
    "# df_MLRtest[[\"RefSt\", \"KNN_Pred\"]].plot()\n",
    "# plt.xticks(rotation=20)\n",
    "\n",
    "# Plot regression\n",
    "# sns.lmplot(x = 'RefSt', y = 'KNN_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"KNN_Pred\"])\n",
    "df_MLRtest[[\"RefSt\", \"KNN_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,7))\n",
    "plt.plot(df_MLRtest[[\"RefSt\", \"KNN_Pred\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% uncomment to run KNN with hyper parameters\n",
    "# # K-Nearest Neighbor stats vs. hyperparameters\n",
    "# def knn_stats():\n",
    "#     knn_aux = pd.DataFrame({'RefSt': Y_MLRtest})\n",
    "\n",
    "#     n_neighbors = [*range(1, 151, 1)]\n",
    "#     r_squared = []\n",
    "#     rmse = []\n",
    "#     mae = []\n",
    "#     time_ms = []\n",
    "\n",
    "#     for i in n_neighbors:\n",
    "#         # Model\n",
    "#         knn = KNeighborsRegressor(n_neighbors=i)\n",
    "\n",
    "#         # Fit\n",
    "#         start_time = float(datetime.now().strftime('%S.%f'))\n",
    "#         knn.fit(X_MLRtrain, Y_MLRtrain)\n",
    "#         end_time = float(datetime.now().strftime('%S.%f'))\n",
    "#         execution_time = (end_time - start_time) * 1000\n",
    "\n",
    "#         # Predict\n",
    "#         knn_aux[\"KNN_Pred\"] = knn.predict(X_MLRtest)\n",
    "        \n",
    "\n",
    "#         # Loss\n",
    "#         r_squared.append(r2_score(knn_aux[\"RefSt\"], knn_aux[\"KNN_Pred\"]))\n",
    "#         rmse.append(mean_squared_error(knn_aux[\"RefSt\"], knn_aux[\"KNN_Pred\"]))\n",
    "#         mae.append(mean_absolute_error(knn_aux[\"RefSt\"], knn_aux[\"KNN_Pred\"]))\n",
    "#         time_ms.append(execution_time)\n",
    "\n",
    "#     knn_stats = pd.DataFrame({'k': n_neighbors, 'r_squared': r_squared, 'rmse': rmse, 'mae': mae, 'time_ms': time_ms})\n",
    "#     knn_stats = knn_stats.set_index('k') # index column (X axis for the plots)\n",
    "#     print(knn_stats)\n",
    "#     plt.plot(knn_aux[[\"RefSt\", \"KNN_Pred\"]])\n",
    "#     # plot\n",
    "#     # knn_stats[[\"r_squared\"]].plot()\n",
    "#     # knn_stats[[\"rmse\"]].plot()\n",
    "#     # knn_stats[[\"mae\"]].plot()\n",
    "#     # knn_stats[[\"time_ms\"]].plot()\n",
    "    \n",
    "# knn_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KNN = pd.DataFrame({'RefSt': praxis_df[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': piera7100_df[\"piera7100_pm2p5_vals\"], 'Temp': df_weather[\"Temperature_C\"], 'RelHum': df_weather[\"Humidity_%\"]})\n",
    "df_KNN[\"KNN\"] = knn.predict(X)\n",
    "df_KNN = pd.DataFrame({'RefSt': praxis_df[\"praxis_pm2p5_vals_adj\"], 'Sensor_KNN': df_KNN[\"KNN\"]})\n",
    "Sensor_plot_KNN = df_KNN[[\"RefSt\",\"Sensor_KNN\"]]\n",
    "Sensor_plot_KNN.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Model\n",
    "rf = RandomForestRegressor(n_estimators = 20 ,random_state = 0)\n",
    "\n",
    "# Fit\n",
    "rf.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# Predict\n",
    "df_MLRtest[\"RF_Pred\"] = rf.predict(X_MLRtest)\n",
    "# print(df_MLRtest)\n",
    "\n",
    "# Plot linear\n",
    "# df_MLRtest[[\"RefSt\", \"RF_Pred\"]].plot()\n",
    "# plt.xticks(rotation = 20)\n",
    "\n",
    "# Plot regression\n",
    "# sns.lmplot(x = 'RefSt', y = 'RF_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"RF_Pred\"])\n",
    "\n",
    "# RF feature importances\n",
    "print('Feature importances:\\n', list(zip(X.columns, rf.feature_importances_)))\n",
    "df_MLRtest[[\"RefSt\", \"RF_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,7))\n",
    "plt.plot(df_MLRtest[[\"RefSt\",\"RF_Pred\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RF = pd.DataFrame({'RefSt': praxis_df[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': piera7100_df[\"piera7100_pm2p5_vals\"], 'Temp': df_weather[\"Temperature_C\"], 'RelHum': df_weather[\"Humidity_%\"]})\n",
    "df_RF[\"RF\"] = rf.predict(X)\n",
    "df_RF = pd.DataFrame({'RefSt': praxis_df[\"praxis_pm2p5_vals_adj\"], 'Sensor_RF': df_RF[\"RF\"]})\n",
    "Sensor_plot_RF = df_RF[[\"RefSt\", \"Sensor_RF\"]]\n",
    "Sensor_plot_RF.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # Kernel Regression\n",
    "# # from sklearn_extensions.kernel_regression import KernelRegression\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# # Models\n",
    "# kr_rbf = KernelRidge(kernel = \"rbf\")\n",
    "# kr_poly = KernelRidge(kernel = \"poly\", degree = 4)\n",
    "\n",
    "# # Fit\n",
    "# kr_rbf.fit(X_MLRtrain, Y_MLRtrain)\n",
    "# kr_poly.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# # Predict\n",
    "# df_MLRtest[\"KR_RBF_Pred\"] = kr_rbf.predict(X_MLRtest)\n",
    "# df_MLRtest[\"KR_Poly_Pred\"] = kr_poly.predict(X_MLRtest)\n",
    "\n",
    "# # Plot linear\n",
    "# df_MLRtest[[\"RefSt\", \"KR_RBF_Pred\", \"KR_Poly_Pred\"]].plot()\n",
    "# plt.xticks(rotation=20)\n",
    "\n",
    "# # Plot regression\n",
    "# sns.lmplot(x = 'RefSt', y = 'KR_RBF_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "# sns.lmplot(x = 'RefSt', y = 'KR_Poly_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# # Loss\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"KR_RBF_Pred\"])\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"KR_Poly_Pred\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # Gaussian Process\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import ConstantKernel, RBF, DotProduct, WhiteKernel\n",
    "\n",
    "# # Kernels definition\n",
    "# # rbf = ConstantKernel(constant_value=1.0, constant_value_bounds=(1e-10, 1e10)) * RBF(length_scale=1.0, length_scale_bounds=(1e-10, 1e10))\n",
    "# rbf = ConstantKernel() * RBF()\n",
    "# dpwh = DotProduct() + WhiteKernel()\n",
    "\n",
    "# # Models\n",
    "# gp_rbf = GaussianProcessRegressor(kernel = rbf, alpha = 150, random_state = 0)\n",
    "# gp_dpwh = GaussianProcessRegressor(kernel = dpwh, alpha = 150, random_state = 0)\n",
    "\n",
    "# # Fit\n",
    "# gp_rbf.fit(X_MLRtrain, Y_MLRtrain)\n",
    "# gp_dpwh.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# # Predict\n",
    "# df_MLRtest[\"GP_RBF_Pred\"] = gp_rbf.predict(X_MLRtest)\n",
    "# df_MLRtest[\"GP_DPWK_Pred\"] = gp_dpwh.predict(X_MLRtest)\n",
    "\n",
    "# # Obtain optimized kernel parameters\n",
    "# # l = gp.kernel_.k2.get_params()['length_scale']\n",
    "# # sigma_f = np.sqrt(gp.kernel_.k1.get_params()['constant_value'])\n",
    "\n",
    "# # Print parameters\n",
    "# print(\"RBF params\", gp_rbf.get_params())\n",
    "# print(\"Dot params\", gp_dpwh.get_params())\n",
    "\n",
    "# # Plot linear\n",
    "# df_MLRtest[[\"RefSt\", \"GP_RBF_Pred\", \"GP_DPWK_Pred\"]].plot()\n",
    "# plt.xticks(rotation = 20)\n",
    "\n",
    "# # Plot regression\n",
    "# sns.lmplot(x = 'RefSt', y = 'GP_RBF_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "# sns.lmplot(x = 'RefSt', y = 'GP_DPWK_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# # Loss\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"GP_RBF_Pred\"])\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"GP_DPWK_Pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using radial basis function kernel\n",
    "# Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Models\n",
    "svr_rbf = SVR(kernel = 'rbf', C = 1e3)#, gamma=0.1)\n",
    "\n",
    "# Fit\n",
    "svr_rbf.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "print('Intercept: \\n', svr_rbf.intercept_)\n",
    "\n",
    "# Predict\n",
    "df_MLRtest[\"SVR_RBF_Pred\"] = svr_rbf.predict(X_MLRtest)\n",
    "\n",
    "# Plot regression\n",
    "sns.lmplot(x = 'RefSt', y = 'SVR_RBF_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"SVR_RBF_Pred\"])\n",
    "\n",
    "df_MLRtest[[\"RefSt\", \"SVR_RBF_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,7))\n",
    "plt.plot(df_MLRtest[[\"RefSt\",\"SVR_RBF_Pred\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Not Ideal as it will take a lot of time to compute\n",
    "# # Support Vector Regression\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "# # Models\n",
    "# svr_lin = SVR(kernel = 'linear', C = 1e3)\n",
    "\n",
    "\n",
    "# # Fit\n",
    "\n",
    "# svr_lin.fit(X_MLRtrain, Y_MLRtrain)\n",
    "\n",
    "# print('Intercept: \\n', svr_lin.intercept_)\n",
    "# # print('Coefficients: \\n', svr_lin.coef_)\n",
    "\n",
    "# # Predict\n",
    "# df_MLRtest[\"SVR_Line_Pred\"] = svr_lin.predict(X_MLRtest)\n",
    "\n",
    "\n",
    "# # Plot regression\n",
    "# sns.lmplot(x = 'RefSt', y = 'SVR_Line_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "\n",
    "# # Loss\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"SVR_Line_Pred\"])\n",
    "\n",
    "# df_MLRtest[[\"RefSt\", \"SVR_Line_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Support Vector Regression using poly (Not Ideal as it takes a lot of time to train)\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "# # Models\n",
    "# svr_poly = SVR(kernel = 'poly', C = 1e3, degree = 3)\n",
    "\n",
    "# # Fit\n",
    "# svr_poly.fit(X_MLRtrain, Y_MLRtrain)\n",
    "# print('Intercept: \\n', svr_poly.intercept_)\n",
    "# #print('Coefficients: \\n', svr_poly.coef_)\n",
    "\n",
    "# # Predict\n",
    "# df_MLRtest[\"SVR_Poly_Pred\"] = svr_poly.predict(X_MLRtest)\n",
    "\n",
    "# # Plot regression\n",
    "\n",
    "# sns.lmplot(x = 'RefSt', y = 'SVR_Poly_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# # Loss\n",
    "\n",
    "# loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"SVR_Poly_Pred\"])\n",
    "# df_MLRtest[[\"RefSt\", \"SVR_Poly_Pred\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SVR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': canary_df[\"canary_pm2p5_vals\"], 'Temp': canary_df[\"canary_temp\"], 'RelHum': canary_df[\"canary_rh\"]})\n",
    "# df_SVR[\"SVR_rbf\"] = svr_rbf.predict(X)\n",
    "# # df_SVR[\"SVR_lin\"] = svr_lin.predict(X)\n",
    "# # df_SVR[\"SVR_poly\"] = svr_poly.predict(X)\n",
    "# df_SVR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_RF': df_SVR[\"SVR_rbf\"]})\n",
    "# # df_SVR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_RF_rbf': df_SVR[\"SVR_rbf\"], 'Sensor_RF_lin': df_SVR[\"SVR_lin\"], 'Sensor_RF_poly': df_SVR[\"SVR_poly\"]})\n",
    "# Sensor_plot_SVR = df_SVR[[\"Sensor_RF\", \"RefSt\"]]\n",
    "# Sensor_plot_SVR.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Normalise data\n",
    "sc = StandardScaler()\n",
    "X_train_NN = sc.fit_transform(X_MLRtrain)\n",
    "X_test_NN = sc.transform(X_MLRtest)\n",
    "Y_MLRtrain_NN = Y_MLRtrain\n",
    "# Model\n",
    "nn = Sequential()\n",
    "\n",
    "# Model - Layers\n",
    "nn.add(InputLayer(input_shape = (3))) # Input layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 1st hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 2nd hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 3rd hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 4th hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 5th hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 6th hidden layer\n",
    "nn.add(Dense(units = 64, activation = 'relu')) # 7th hidden layer\n",
    "nn.add(Dense(units = 1)) # Output layer\n",
    "\n",
    "nn.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fit\n",
    "history = nn.fit(X_train_NN, Y_MLRtrain_NN, batch_size = 5, epochs = 20)\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history['loss'][5:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Predict\n",
    "df_MLRtest[\"NN_Pred\"] = nn.predict(X_MLRtest)\n",
    "print(df_MLRtest)\n",
    "\n",
    "# Plot linear\n",
    "# df_MLRtest[[\"RefSt\", \"NN_Pred\"]].plot()\n",
    "# plt.xticks(rotation=20)\n",
    "\n",
    "# Plot regression\n",
    "sns.lmplot(x = 'RefSt', y = 'NN_Pred', data = df_MLRtest, fit_reg = True, line_kws = {'color': 'orange'}) \n",
    "\n",
    "# Loss\n",
    "loss_functions(y_true = df_MLRtest[\"RefSt\"], y_pred = df_MLRtest[\"NN_Pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,7))\n",
    "# df_SVR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_O1': canary_df[\"canary_pm2p5_vals\"], 'Temp': canary_df[\"canary_temp\"], 'RelHum': canary_df[\"canary_rh\"]})\n",
    "# df_SVR[\"SVR_rbf\"] = svr_rbf.predict(X)\n",
    "# df_SVR[\"SVR_lin\"] = svr_lin.predict(X)\n",
    "# df_SVR[\"SVR_poly\"] = svr_poly.predict(X)\n",
    "df_NN = pd.DataFrame({'RefSt': praxis_df[\"praxis_pm2p5_vals_adj\"], 'Sensor_NN': df_MLRtest[\"NN_Pred\"]})\n",
    "# df_SVR = pd.DataFrame({'RefSt': praxis_df2[\"praxis_pm2p5_vals_adj\"], 'Sensor_RF_rbf': df_SVR[\"SVR_rbf\"], 'Sensor_RF_lin': df_SVR[\"SVR_lin\"], 'Sensor_RF_poly': df_SVR[\"SVR_poly\"]})\n",
    "Sensor_plot_NN = df_NN[[\"Sensor_NN\", \"RefSt\"]]\n",
    "plt.plot(Sensor_plot_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
